{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "architecture_id": "workbench-canonical-v1.4",
  "version": "1.4",
  "previous_version": "1.3",
  "status": "active",
  "created_date": "2024-11-29",
  "updated_date": "2025-12-01",
  "owner": "Architect",
  "revision_notes": "Added Epic Processing Pipeline component (PIPELINE-001) with phase architecture, artifact storage structure, schema versioning, and pipeline-orchestrator integration contract. Added Configuration Architecture section with immutability constraint. Formalized 5 Architecture Decision Records (ADR-001 through ADR-005). Updated repository structure with improved organization.",
  
  "system_overview": {
    "description": "Workbench AI is a development environment where a coordinated Workforce of AI roles (PM, BA, Architect, Developers, Mentors, QA) collaboratively delivers working software through structured workflows and canonical artifacts. The Epic Processing Pipeline automates Epic creation, reducing manual coordination from 2+ hours to <10 minutes.",
    "core_principles": [
      "Separation of Concerns: Each role has distinct responsibilities with clear boundaries",
      "Artifact-Driven Workflow: Roles communicate via structured JSON artifacts, not ad-hoc conversation",
      "Single Source of Truth: Canonical documents define requirements, architecture, and backlog",
      "Read-Only AI Access: AI roles propose changes via JSON; only backend touches filesystem/git",
      "Incremental Delivery: Work proceeds in testable increments with quality gates",
      "Automated Orchestration: Pipeline and Workforce Orchestrator coordinate multi-role workflows",
      "Configuration Immutability: Configuration is set once via environment variables, never mutated"
    ],
    "architectural_patterns": [
      "Event-Driven Orchestration: Orchestrator dispatches work to roles based on ticket state",
      "Multi-Agent Collaboration: Multiple Developer Workers propose solutions independently",
      "Review & Integration: Developer Mentor synthesizes proposals into canonical implementation",
      "Branch-Based Development: workforce-sandbox → main via PR with automated tests",
      "State Machine Pipeline: Epic Processing Pipeline orchestrates PM → Arch → BA → Consolidation phases",
      "Centralized Configuration: Single config.py with Pydantic Settings, environment variable overrides"
    ]
  },
  
  "configuration_architecture": {
    "principle": "Configuration Immutability",
    "constraint": "Monkeypatch MUST NOT be used for configuration or path overrides",
    "description": "Centralized configuration management with Pydantic Settings and environment variable overrides",
    
    "configuration_sources": {
      "priority_order": [
        "1. Environment variables (WORKBENCH_* prefix)",
        "2. .env file (if present)",
        "3. Default values in Settings class"
      ],
      "immutability": "Settings object is created once at module import and never mutated"
    },
    
    "configuration_module": {
      "file": "config.py",
      "location": "Repository root",
      "implementation": "Pydantic Settings with BaseSettings",
      "key_settings": {
        "PROJECT_ROOT": "Path(__file__).resolve().parent",
        "APP_ROOT": "PROJECT_ROOT / 'app'",
        "WORKFORCE_ROOT": "PROJECT_ROOT / 'workforce'",
        "DATA_ROOT": "PROJECT_ROOT / 'data'",
        "DB_PATH": "DATA_ROOT / 'workbench_ai.db'",
        "LOGS_ROOT": "DATA_ROOT / 'logs'",
        "EPICS_ROOT": "DATA_ROOT / 'epics'",
        "CANON_ROOT": "WORKFORCE_ROOT / 'canon'",
        "SCHEMAS_ROOT": "CANON_ROOT / 'schemas'"
      },
      "helper_functions": {
        "epic_dir(epic_id)": "Returns Path to data/epics/{epic_id}/",
        "canonical_path(filename)": "Returns Path to workforce/canon/{filename}",
        "schema_path(name, version)": "Returns Path to workforce/canon/schemas/{name}_{version}.json"
      }
    },
    
    "test_isolation": {
      "mechanism": "Environment variable override before Settings creation",
      "implementation": {
        "file": "tests/conftest.py",
        "fixture": "setup_test_environment",
        "scope": "session",
        "autouse": true,
        "pattern": [
          "1. Set WORKBENCH_DATA_ROOT environment variable to tmp_path",
          "2. Import config module (Settings reads env var)",
          "3. All application code uses test-isolated paths"
        ]
      }
    },
    
    "prohibited_patterns": {
      "monkeypatch_config": {
        "pattern": "monkeypatch.setattr(settings, 'DATA_ROOT', ...)",
        "reason": "Violates configuration immutability",
        "alternative": "Use environment variables before config import"
      },
      "direct_mutation": {
        "pattern": "settings.DATA_ROOT = new_path",
        "reason": "Bypasses Pydantic validation and breaks immutability",
        "alternative": "Use environment variables and recreate Settings instance"
      },
      "config_caching": {
        "pattern": "DATA_ROOT = settings.DATA_ROOT  # At module level",
        "reason": "Caches value before test env var override",
        "alternative": "Always reference settings.DATA_ROOT dynamically or use helper functions"
      }
    },
    
    "allowed_monkeypatch_uses": {
      "description": "Monkeypatch is allowed for non-configuration test doubles",
      "examples": [
        "Mocking external API calls",
        "Stubbing database connections",
        "Faking datetime.now() for time-dependent tests",
        "Replacing functions with test doubles"
      ],
      "rule": "Monkeypatch anything EXCEPT config.settings and its attributes"
    }
  },
  
  "epic_processing_pipeline": {
    "component": "Epic Processing Pipeline",
    "epic_id": "PIPELINE-001",
    "purpose": "Automate Epic processing through PM → Architect → BA → Consolidation phases, producing canonical Epic artifacts without manual role coordination",
    "status": "Active",
    "version": "1.0",
    
    "architecture": {
      "pattern": "State Machine Pipeline",
      "execution_model": "Synchronous (sequential phase execution)",
      "concurrency": "Single-instance for MVP (no concurrent pipeline execution)",
      "idempotency": "Pipeline is idempotent (safe to re-run with same input)"
    },
    
    "phases": {
      "pm_phase": {
        "name": "PM Phase",
        "story_id": "PIPELINE-102",
        "responsibility": "Validate Epic JSON structure and completeness",
        "inputs": ["Epic JSON from PM"],
        "outputs": ["Validated Epic JSON"],
        "validation": [
          "Required fields exist (epic_id, title, description, acceptance_criteria, scope)",
          "epic_id format matches ^[A-Z]+-\\d{3}$",
          "acceptance_criteria is non-empty array"
        ],
        "timeout": "1 minute",
        "error_handling": "Fail with specific field missing/invalid error"
      },
      "architect_phase": {
        "name": "Architect Phase",
        "story_id": "PIPELINE-103",
        "responsibility": "Attach Canonical Architecture reference to Epic",
        "inputs": ["Validated Epic JSON", "Canonical Architecture JSON v1.3+"],
        "outputs": ["Epic JSON with canonical_architecture_ref"],
        "operations": [
          "Load Canonical Architecture JSON from workforce/canon/",
          "Extract architecture_id, version, location",
          "Add canonical_architecture_ref to Epic",
          "Perform high-level architecture compatibility check"
        ],
        "timeout": "2 minutes",
        "error_handling": "Fail if Canonical Architecture JSON not found or incompatible"
      },
      "ba_phase": {
        "name": "BA Phase",
        "story_id": "PIPELINE-104",
        "responsibility": "Generate BA Addendum from template and attach reference to Epic",
        "inputs": ["Epic JSON with architecture_ref", "BA Addendum Template v1.0"],
        "outputs": ["Epic JSON with ba_addendum_ref", "Generated ba_addendum.json"],
        "operations": [
          "Load BA Addendum Template from workforce/canon/ba_addendum_template_v1.json",
          "Customize template: epic_id, addendum_id, created_date, references",
          "Save BA Addendum to data/epics/{epic_id}/ba_addendum.json",
          "Add ba_addendum_ref to Epic"
        ],
        "customization": "Template-based with minimal customization for MVP (epic_id, references). Future: dynamic LLM-driven generation.",
        "timeout": "5 minutes",
        "error_handling": "Fail if template not found or customization fails"
      },
      "consolidation_phase": {
        "name": "Consolidation Phase",
        "story_id": "PIPELINE-105",
        "responsibility": "Generate final canonical Epic JSON with orchestration plan, quality models, and markdown export",
        "inputs": ["Epic JSON with architecture_ref and ba_addendum_ref"],
        "outputs": ["canonical_epic.json", "canonical_epic.md"],
        "operations": [
          "Generate orchestration_plan section (simple/medium/complex flows)",
          "Generate quality_models section with references to BA models",
          "Assemble final canonical_epic.json with all sections",
          "Generate canonical_epic.md markdown export",
          "Validate canonical_epic.json against Epic schema v1.0",
          "Save artifacts to data/epics/{epic_id}/"
        ],
        "timeout": "2 minutes",
        "error_handling": "Fail if schema validation fails or file write fails"
      }
    },
    
    "artifact_storage": {
      "structure": "data/epics/{epic_id}/",
      "files": {
        "input_epic.json": "PM's original Epic input",
        "canonical_architecture.json": "Reference copy of Canonical Architecture v1.3+",
        "ba_addendum.json": "Generated BA Addendum v1.0",
        "canonical_epic.json": "Final Epic with all sections",
        "canonical_epic.md": "Human-readable markdown export",
        "pipeline_status.json": "Status tracking (state, phase history, errors)",
        "pipeline.log": "Execution log (timestamps, phase durations, errors)"
      }
    },
    
    "status_tracking": {
      "states": ["pending", "in_progress", "pm_phase", "arch_phase", "ba_phase", "consolidation", "complete", "failed"],
      "persistence": "data/epics/{epic_id}/pipeline_status.json",
      "resume_capability": "Pipeline can resume from last successful phase if execution interrupted",
      "status_schema": {
        "epic_id": "string",
        "status": "enum (states)",
        "current_phase": "string|null",
        "phase_history": [
          {
            "phase": "string",
            "status": "started|completed|failed",
            "started_at": "ISO timestamp",
            "completed_at": "ISO timestamp",
            "duration_seconds": "number"
          }
        ],
        "errors": [
          {
            "phase": "string",
            "message": "string",
            "context": "object",
            "timestamp": "ISO timestamp"
          }
        ],
        "artifacts": {
          "canonical_epic_json": "path|null",
          "canonical_epic_md": "path|null",
          "ba_addendum": "path|null"
        }
      }
    },
    
    "error_handling": {
      "strategy": "Fail-fast (first error stops pipeline)",
      "error_structure": {
        "phase": "string (which phase failed)",
        "message": "string (what went wrong)",
        "context": "object (input artifact, line number, etc.)",
        "timestamp": "ISO timestamp",
        "actionable_guidance": "string (what to fix)"
      },
      "error_persistence": "Errors logged to pipeline.log and pipeline_status.json",
      "error_recovery": "Pipeline can be re-run after fixing input Epic or missing dependencies"
    },
    
    "cli_interface": {
      "story_id": "PIPELINE-108",
      "commands": {
        "run": "pipeline run --epic-file <path>",
        "status": "pipeline status --epic-id <epic_id>",
        "errors": "pipeline errors --epic-id <epic_id>"
      },
      "flags": {
        "verbose": "--verbose (detailed logging)",
        "force": "--force (re-run even if complete)"
      },
      "exit_codes": {
        "0": "Success",
        "1": "Validation error (PM phase)",
        "2": "Architecture error (Architect phase)",
        "3": "BA Addendum error (BA phase)",
        "4": "Consolidation error (Consolidation phase)",
        "5": "File system error",
        "6": "Timeout"
      }
    },
    
    "performance_requirements": {
      "total_pipeline_time": "<10 minutes for standard Epic (8-13 story points)",
      "phase_timeouts": {
        "pm_phase": "1 minute",
        "architect_phase": "2 minutes",
        "ba_phase": "5 minutes",
        "consolidation_phase": "2 minutes"
      },
      "success_rate": "≥95% for well-formed Epic JSON"
    },
    
    "constraints": {
      "concurrency": "Single-instance for MVP (no concurrent execution)",
      "idempotency": "Safe to re-run with same input (produces same output)",
      "template_dependency": "Requires BA Addendum Template v1.0 in workforce/canon/",
      "file_system_access": "Requires read/write access to data/epics/ directory"
    },
    
    "integration_points": {
      "workforce_orchestrator": {
        "direction": "Pipeline outputs → Workforce Orchestrator consumes",
        "artifacts": {
          "canonical_epic.json": "Workforce Orchestrator reads to execute tickets",
          "ba_addendum.json": "Developer Mentor uses for quality gates",
          "canonical_architecture.json": "Developer uses for design constraints"
        },
        "contract": {
          "required_sections_in_canonical_epic": [
            "canonical_architecture_ref (architecture_id, version, location)",
            "ba_addendum_ref (addendum_id, version, location)",
            "orchestration_plan (simple_tickets, medium_tickets, complex_tickets)",
            "quality_models (proposal_quality_model, test_coverage_model, etc.)"
          ],
          "validation": "Workforce Orchestrator validates canonical_epic.json against Epic schema v1.0",
          "error_handling": "If invalid, Workforce Orchestrator rejects Epic and logs error"
        }
      }
    }
  },
  
  "schema_versioning": {
    "description": "All canonical artifacts are versioned to enable pipeline compatibility and evolution",
    "current_versions": {
      "epic_json": "v1",
      "canonical_architecture": "v1.4",
      "ba_addendum_template": "v1",
      "commit_plan": "v1",
      "integration_notes": "v1"
    },
    "schema_locations": {
      "epic_schema": "workforce/canon/schemas/epic_v1.json",
      "canonical_epic_schema": "workforce/canon/schemas/canonical_epic_v1.json",
      "ba_addendum_schema": "workforce/canon/schemas/ba_addendum_v1.json",
      "canonical_architecture": "workforce/canon/canonical_architecture_v1.4.json",
      "ba_addendum_template": "workforce/canon/ba_addendum_template_v1.json",
      "commit_plan_schema": "workforce/canon/schemas/commit_plan_v1.json",
      "integration_notes_schema": "workforce/canon/schemas/integration_notes_v1.json"
    },
    "version_compatibility": {
      "epic_processing_pipeline": {
        "supports_epic_json": ["v1"],
        "supports_canonical_architecture": ["v1.3", "v1.4"],
        "supports_ba_addendum_template": ["v1"]
      }
    },
    "evolution_process": [
      "1. Create new schema version (e.g., epic_v1.1.json)",
      "2. Update pipeline to support both old and new versions",
      "3. Deprecate old version after 2 quarters",
      "4. Remove old version support after 1 year"
    ],
    "breaking_changes": {
      "require_major_version_bump": [
        "Removing required fields",
        "Changing field types",
        "Renaming fields without aliases"
      ],
      "require_minor_version_bump": [
        "Adding optional fields",
        "Adding new enum values",
        "Extending arrays"
      ]
    }
  },
  
  "repository_structure": {
    "description": "Repository organized into four main directories: app/ (user-facing), workforce/ (AI engine), data/ (mutable runtime), tests/ (test suite)",
    "structure": {
      "config.py": {
        "location": "Repository root",
        "description": "Centralized configuration with Pydantic Settings"
      },
      "app": {
        "path": "app/",
        "description": "FastAPI application (user-facing)",
        "subdirectories": {
          "main.py": "FastAPI entrypoint",
          "routers": "API routes (auth.py, repo_view.py)",
          "services": "Business logic (email_service.py, repo_reader.py)",
          "schemas": "Pydantic models (auth.py, repo_view.py)",
          "models": "Database models (sessions.py)",
          "templates": "Jinja2 templates (auth/)"
        }
      },
      "workforce": {
        "path": "workforce/",
        "description": "AI workforce engine (core logic)",
        "subdirectories": {
          "orchestrator.py": "Main Orchestrator: WORK-* ticket execution",
          "pipeline": "Epic Processing Pipeline (PIPELINE-001) - epic_pipeline.py, status.py, phases/, cli.py",
          "roles": "AI role implementations (product_manager.py, architect.py, business_analyst.py, developer.py, developer_mentor.py)",
          "canon": "Canonical artifacts (canonical_architecture_v*.json, ba_addendum_template_v*.json, schemas/)",
          "utils": "Shared utilities (schema_validator.py, file_ops.py, git_ops.py)",
          "backlog": "Product backlog (backlog.json)"
        }
      },
      "data": {
        "path": "data/",
        "description": "Mutable runtime data",
        "subdirectories": {
          "workbench_ai.db": "SQLite database",
          "logs": "Application, workforce, and pipeline logs",
          "epics": "Per-Epic artifacts (created by pipeline) - data/epics/{epic_id}/"
        }
      },
      "tests": {
        "path": "tests/",
        "description": "Test suite",
        "subdirectories": {
          "conftest.py": "Test isolation via env vars (setup_test_environment fixture)",
          "app": "Application tests (test_auth.py, test_repo_view.py)",
          "workforce": "Workforce tests (test_orchestrator.py, pipeline/test_epic_pipeline.py, etc.)",
          "fixtures": "Test fixtures (sample_epics/, canonical_architecture_v1.4.json, ba_addendum_template_v1.json)"
        }
      },
      "docs": {
        "path": "docs/",
        "description": "Documentation",
        "subdirectories": {
          "architecture": "Architecture documentation (canonical-architecture-v*.md)",
          "adr": "Architecture Decision Records (ADR-001 through ADR-005)",
          "guides": "User guides (pipeline_usage.md, epic_creation.md)"
        }
      }
    }
  },
  
  "workforce_architecture": {
    "description": "Multi-agent AI workforce for collaborative software development",
    "epic_id": "WORKFORCE-001",
    "roles": {
      "product_manager": {
        "responsibilities": ["Define Epics and stories", "Break down requirements", "Define acceptance criteria", "Prioritize backlog"],
        "outputs": ["Epic JSON", "Story definitions", "Backlog prioritization"]
      },
      "architect": {
        "responsibilities": ["Review Epic for architectural feasibility", "Design technical architecture", "Define integration points", "Maintain Canonical Architecture"],
        "outputs": ["Architecture design", "Technical feasibility assessment", "Canonical Architecture updates"]
      },
      "business_analyst": {
        "responsibilities": ["Define operational criteria", "Generate BA Addendum (quality models, test coverage, approval rules)", "Define rework communication contracts", "Specify human approval rules"],
        "outputs": ["BA Addendum JSON with 5 operational models"]
      },
      "developer_worker": {
        "responsibilities": ["Receive WORK-* ticket assignments", "Propose implementation as Proposal JSON", "Include code changes, test plan, risk assessment", "Work independently (multiple Developers may work on same ticket)"],
        "outputs": ["Proposal JSON with code changes, tests, risks"]
      },
      "developer_mentor": {
        "responsibilities": ["Review Developer proposals", "Synthesize best ideas from multiple proposals", "Produce canonical CommitPlan", "Ensure quality gates met", "Request rework if needed", "Coordinate with /workforce/commit backend"],
        "outputs": ["CommitPlan JSON", "IntegrationNotes JSON", "Rework requests"]
      },
      "program_orchestrator": {
        "responsibilities": ["Route Epics through PM → Architect → BA workflow", "Consolidate Epic outputs into canonical_epic.json", "Coordinate multi-role workflows", "Assign WORK-* tickets to Developers"],
        "outputs": ["canonical_epic.json", "Ticket assignments", "Workflow coordination"]
      }
    },
    "multi_agent_collaboration_pattern": {
      "description": "Multiple Developer Workers independently propose solutions; Developer Mentor synthesizes",
      "ticket_execution_flow": [
        "1. Orchestrator assigns WORK-* ticket to Developer(s)",
        "2. Developer(s) independently generate Proposal JSON",
        "3. Developer Mentor reviews all proposals",
        "4. Developer Mentor synthesizes CommitPlan",
        "5. CommitPlan sent to /workforce/commit backend",
        "6. Backend executes commit and creates PR"
      ],
      "developer_deployment_tiers": {
        "simple_tickets": {
          "description": "Single Developer Worker",
          "criteria": "Well-defined, low risk, isolated changes"
        },
        "medium_tickets": {
          "description": "2-3 Developer Workers",
          "criteria": "Moderate complexity, some integration points"
        },
        "complex_tickets": {
          "description": "3-5 Developer Workers",
          "criteria": "High complexity, significant architectural impact"
        }
      }
    }
  },
  
  "integration_contracts": {
    "pipeline_to_workforce_orchestrator": {
      "description": "Pipeline output feeds Workforce Orchestrator input for ticket execution",
      "pipeline_deliverables": {
        "canonical_epic.json": "Complete Epic with architecture/BA references, orchestration_plan, quality_models",
        "canonical_epic.md": "Human-readable Epic export",
        "ba_addendum.json": "BA operational criteria models"
      },
      "workforce_orchestrator_consumption": {
        "canonical_epic_json": "Read to understand Epic structure and orchestration plan",
        "orchestration_plan": "Determine Developer deployment pattern (simple/medium/complex)",
        "quality_models": "Reference for proposal quality thresholds",
        "ba_addendum_json": "Load for detailed quality criteria and human approval rules"
      },
      "contract_validation": {
        "pipeline": "Validates canonical_epic.json against Epic schema v1.0",
        "workforce_orchestrator": "Validates required sections exist (architecture_ref, ba_addendum_ref, orchestration_plan, quality_models)"
      },
      "error_handling": {
        "invalid_canonical_epic": "Workforce Orchestrator rejects Epic and logs error",
        "missing_ba_addendum": "Workforce Orchestrator uses default quality models",
        "missing_orchestration_plan": "Workforce Orchestrator defaults to simple ticket flow"
      }
    },
    "developer_to_mentor_contract": {
      "description": "Contract between Developer Workers and Developer Mentor",
      "developer_output": {
        "format": "Proposal JSON",
        "required_fields": ["proposal_id", "ticket_id", "code_changes", "test_plan", "risk_assessment"],
        "quality_requirements": "Must meet minimum quality thresholds across all 5 dimensions"
      },
      "mentor_output": {
        "format": "CommitPlan JSON",
        "contains": ["Synthesized code changes", "Validated test plan", "Integration notes", "Quality assessment"]
      },
      "rework_protocol": {
        "trigger": "Proposal quality score < 7.0",
        "action": "Mentor requests rework with clear feedback",
        "iteration": "Developer revises and resubmits"
      }
    }
  },
  
  "architecture_decision_records": [
    {
      "adr_id": "ADR-001",
      "title": "Pipeline Synchronous Execution",
      "decision": "Phases execute sequentially (synchronous) for MVP",
      "rationale": "Linear dependencies between phases, simpler implementation and debugging, acceptable performance (<10 minutes)",
      "consequences": {
        "positive": ["Simple implementation", "Easier debugging", "Predictable performance"],
        "negative": ["Cannot parallelize independent work", "May need refactoring for performance"]
      },
      "status": "Accepted",
      "date": "2025-12-01"
    },
    {
      "adr_id": "ADR-002",
      "title": "Template-Based BA Addendum Generation",
      "decision": "Use template-based generation with minimal customization for MVP",
      "rationale": "WORKFORCE-001-BA-ADDENDUM is high-quality reference, fast execution (<10 seconds), simple implementation, consistent quality",
      "consequences": {
        "positive": ["Fast (<10s)", "Consistent quality", "Simple implementation"],
        "negative": ["Less customization per Epic", "Manual template updates needed"]
      },
      "future": "Enhance with LLM-driven customization for Epic-specific operational criteria",
      "status": "Accepted",
      "date": "2025-12-01"
    },
    {
      "adr_id": "ADR-003",
      "title": "File-Based Artifact Persistence",
      "decision": "Use file system with structured directories for artifact persistence",
      "rationale": "Matches existing Workforce pattern, simple implementation (no database), easy to inspect and debug, version control friendly, natural isolation per Epic",
      "consequences": {
        "positive": ["Simple", "Debuggable", "Git-friendly", "Natural isolation"],
        "negative": ["No transactional guarantees", "No query capabilities", "Concurrent access requires locking"]
      },
      "future": "Consider database at scale (>1000 Epics)",
      "status": "Accepted",
      "date": "2025-12-01"
    },
    {
      "adr_id": "ADR-004",
      "title": "Centralized Configuration",
      "decision": "Use centralized config.py at repository root with Pydantic Settings",
      "rationale": "Single source of truth for paths, type safety with Pydantic, environment variable support, test isolation via env vars, no hard-coded paths",
      "consequences": {
        "positive": ["Consistent", "Type-safe", "Testable", "No hard-coded paths"],
        "negative": ["Import order matters", "One more dependency (pydantic-settings)"]
      },
      "status": "Accepted",
      "date": "2025-12-01"
    },
    {
      "adr_id": "ADR-005",
      "title": "Configuration Immutability - No Monkeypatch",
      "decision": "Configuration MUST use environment variables exclusively. Monkeypatch MUST NOT be used for configuration",
      "rationale": "Respects Pydantic Settings immutability, tests real configuration behavior, works across module boundaries, future-proof against Pydantic changes",
      "consequences": {
        "positive": ["Immutable config", "Reliable", "Production-fidelity", "Works across modules"],
        "negative": ["Requires tmp_path_factory", "Import order sensitive", "Session-wide isolation only"]
      },
      "enforcement": "Developer Mentor MUST reject monkeypatch-based configuration mutation",
      "status": "Accepted (ARCHITECTURAL HARD CONSTRAINT)",
      "date": "2025-12-01"
    }
  ],
  
  "architectural_risks": {
    "template_drift": {
      "description": "BA Addendum template (v1.0) may become outdated as BA models evolve",
      "likelihood": "medium",
      "impact": "high",
      "mitigation": "Version BA Addendum template explicitly (v1.0, v1.1, v1.2). Pipeline validates template version compatibility. Add template_version field to ba_addendum_ref. Document template update process."
    },
    "concurrent_pipeline_execution": {
      "description": "Multiple pipelines running concurrently may conflict on shared resources",
      "likelihood": "low_for_mvp_high_for_future",
      "impact": "high",
      "mitigation": "MVP: Document single-instance constraint. Each Epic has isolated directory. Future: Add file locking or pipeline queue."
    },
    "schema_evolution": {
      "description": "Epic JSON schema or artifact schemas evolve, breaking pipeline validation",
      "likelihood": "medium",
      "impact": "high",
      "mitigation": "Version all schemas. Pipeline supports multiple schema versions. Schema validation uses explicit version. Provide schema migration tools."
    },
    "phase_execution_time": {
      "description": "Complex Epics may take >10 minutes to process (especially BA phase with future LLM generation)",
      "likelihood": "low_for_mvp_medium_for_future",
      "impact": "medium",
      "mitigation": "Set timeout at phase level (PM: 1min, Arch: 2min, BA: 5min, Consolidation: 2min). Log phase duration. Monitor and optimize slow phases. For MVP: Template-based BA generation is fast (<10 seconds)."
    }
  },
  
  "tech_stack": {
    "language": "Python 3.11+",
    "framework": "FastAPI",
    "validation": "Pydantic",
    "settings": "Pydantic Settings",
    "database": "SQLite",
    "orm": "SQLAlchemy",
    "testing": "pytest",
    "templating": "Jinja2",
    "ai_llm": "Anthropic Claude API (claude-sonnet-4-20250514)"
  },
  
  "future_considerations": [
    "Pipeline UI for monitoring (out of scope for MVP)",
    "Pipeline scheduling/automation (out of scope for MVP)",
    "Parallel pipeline execution for performance",
    "LLM-driven BA addendum customization",
    "Database migration for high Epic volume (>1000 Epics)",
    "Multi-tenant pipeline isolation"
  ]
}
