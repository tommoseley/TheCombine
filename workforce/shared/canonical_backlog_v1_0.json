{
  "type": "canonical_backlog",
  "version": 1,
  "sections": {
    "summary": {
      "blocks": [
        {
          "id": "summary-1",
          "type": "paragraph",
          "content": "The Canonical Backlog contains 22 INVEST-compliant user stories for Phase 1 MVP (Months 1-3), organized by Epic themes: Authentication, Workspace Management, PM Discovery, Epic Generation, Architecture Generation, Backlog Generation, Export, Real-Time Streaming, Error Handling, and Repo View. All stories trace to the Canonical Epic phases and Canonical Architecture components."
        },
        {
          "id": "summary-2",
          "type": "paragraph",
          "content": "Total Phase 1 effort: 117 story points across 22 stories. Stories follow INVEST principles (Independent, Negotiable, Valuable, Estimable, Small, Testable) and include clear acceptance criteria, dependencies, and technical implementation notes aligned with the Python/FastAPI architecture."
        },
        {
          "id": "summary-3",
          "type": "paragraph",
          "content": "Phase 2 and Phase 3 stories are included at high-level for roadmap visibility, with detailed breakdown deferred until Phase 1 completion per Epic guidance."
        }
      ]
    },
    "phase_1_stories": {
      "blocks": [
        {
          "id": "phase1-heading",
          "type": "heading",
          "level": 2,
          "content": "Phase 1: Core Platform / MVP (Months 1-3)"
        },
        {
          "id": "phase1-summary",
          "type": "paragraph",
          "content": "Phase 1 delivers the core orchestrated workflow: user authentication, workspace creation, PM discovery (questions and Epic generation), Architecture generation, Backlog generation, export functionality, and read-only repository introspection. All features support single-user workflows with real-time streaming feedback."
        },
        {
          "id": "theme-auth-heading",
          "type": "heading",
          "level": 3,
          "content": "Theme: Authentication & User Management"
        },
        {
          "id": "story-auth-100",
          "type": "story",
          "data": {
            "id": "AUTH-101",
            "title": "Magic link authentication (email only)",
            "user_story": "As a user, I want to access my workspaces via a magic link sent to my email so that I can use the platform securely without third-party auth providers.",
            "acceptance_criteria": [
              "Landing page form accepts email address (required, valid format).",
              "On submit, system generates a random 128-bit token and stores it in a new `sessions` table with fields: id (UUID), email, token_hash, expires_at (default 7 days), created_at.",
              "Magic link emailed via SMTP (stdlib smtplib) or simple HTTP POST to a configurable mail provider URL (env var, no SDK).",
              "Magic link contains a one-time token endpoint: GET /magic-login?token=...; on success, backend sets secure HttpOnly cookie with opaque session ID and redirects to workspace list.",
              "All protected routes use a FastAPI dependency that validates the session cookie against the `sessions` table; invalid/expired sessions return 401 and redirect to login page.",
              "Logout endpoint deletes the session record and clears the cookie.",
              "If email sending fails, user sees a friendly error with 'Retry' option; failures logged to agent/system logs."
            ],
            "story_points": 5,
            "phase": "Phase 1",
            "epic_feature": "Authentication & Security",
            "dependencies": [],
            "technical_notes": "Pure internal session table, no OAuth or external auth SDKs. Use stdlib smtplib or a minimal HTTP call to a configurable mail gateway. Keep implementation behind an EmailService interface for later Phase 2 swap to third-party providers."
          }
        },
        {
          "id": "theme-workspace-heading",
          "type": "heading",
          "level": 3,
          "content": "Theme: Workspace Management"
        },
        {
          "id": "story-wrk-100",
          "type": "story",
          "data": {
            "id": "WRK-100",
            "title": "Create new workspace for product idea",
            "user_story": "As a user, I want to create a new workspace by entering an idea name and description so that I can start the discovery workflow.",
            "acceptance_criteria": [
              "Form accepts idea name (required, max 200 chars) and description (optional, max 2000 chars)",
              "POST /workspaces creates workspace record in database with unique UUID",
              "Workspace initialized with status='active' and pipeline_state.stage='pm_questions'",
              "User redirected to workspace detail page showing initial status",
              "Validation errors displayed inline (empty name, length exceeded)",
              "Database errors show user-friendly retry option"
            ],
            "story_points": 3,
            "phase": "Phase 1",
            "epic_feature": "Workspace Management",
            "dependencies": ["AUTH-101"],
            "technical_notes": "FastAPI POST endpoint, SQLAlchemy workspace and pipeline_state models, HTMX form submission with server-side validation"
          }
        },
        {
          "id": "story-wrk-101",
          "type": "story",
          "data": {
            "id": "WRK-101",
            "title": "View list of all my workspaces",
            "user_story": "As a user, I want to see a list of all my workspaces (active and archived) so that I can navigate to them.",
            "acceptance_criteria": [
              "GET /workspaces returns all workspaces where user_id matches authenticated user",
              "List displays: name, description preview (first 100 chars), status, current pipeline stage, updated_at timestamp",
              "Workspaces sorted by updated_at DESC (most recent first)",
              "Click workspace name opens workspace detail view",
              "Empty state shows message: 'No workspaces yet. Create your first idea!'",
              "Pagination if user has more than 50 workspaces"
            ],
            "story_points": 2,
            "phase": "Phase 1",
            "epic_feature": "Workspace Management",
            "dependencies": ["WRK-100"],
            "technical_notes": "Jinja2 template for workspace list, SQLAlchemy query with user_id filter and order_by, HTMX for pagination"
          }
        },
        {
          "id": "story-wrk-102",
          "type": "story",
          "data": {
            "id": "WRK-102",
            "title": "Archive workspace",
            "user_story": "As a user, I want to archive completed or abandoned workspaces so that my workspace list stays organized.",
            "acceptance_criteria": [
              "Archive button visible on workspace detail page",
              "Confirmation prompt: 'Archive this workspace? You can restore it later.'",
              "PATCH /workspaces/{id} updates workspace.status='archived'",
              "Archived workspaces hidden from default workspace list view",
              "'Show Archived' toggle reveals archived workspaces in list",
              "Archived workspaces cannot advance pipeline (approval buttons disabled)"
            ],
            "story_points": 2,
            "phase": "Phase 1",
            "epic_feature": "Workspace Management",
            "dependencies": ["WRK-101"],
            "technical_notes": "HTMX button with hx-patch, SQLAlchemy update, confirmation modal, list view filter on status field"
          }
        },
        {
          "id": "story-wrk-103",
          "type": "story",
          "data": {
            "id": "WRK-103",
            "title": "Delete workspace (soft delete)",
            "user_story": "As a user, I want to permanently delete workspaces so that I can remove unwanted ideas from my account.",
            "acceptance_criteria": [
              "Delete button visible only for archived workspaces",
              "Confirmation prompt: 'Permanently delete this workspace? This cannot be undone.'",
              "DELETE /workspaces/{id} updates workspace.status='deleted' (soft delete)",
              "Deleted workspaces excluded from all user-facing queries",
              "Deleted workspaces retained in database for audit purposes (no hard delete)",
              "Cascade: Related canonical_documents, pipeline_state, agent_logs retained but inaccessible via UI"
            ],
            "story_points": 2,
            "phase": "Phase 1",
            "epic_feature": "Workspace Management",
            "dependencies": ["WRK-102"],
            "technical_notes": "Soft delete via status='deleted', SQLAlchemy query filters exclude deleted workspaces, confirmation modal"
          }
        },
        {
          "id": "theme-pm-heading",
          "type": "heading",
          "level": 3,
          "content": "Theme: PM Discovery Workflow"
        },
        {
          "id": "story-pm-100",
          "type": "story",
          "data": {
            "id": "PM-100",
            "title": "Generate PM clarifying questions",
            "user_story": "As a user, I want to receive clarifying questions about my product idea so that the system understands my vision and can generate a tailored Epic.",
            "acceptance_criteria": [
              "After workspace creation, Orchestrator Core spawns 3 PM agents in parallel via asyncio.gather",
              "Each PM agent receives idea name and description, generates 3-6 clarifying questions",
              "PM Mentor consolidates agent outputs into 8-12 unique, non-duplicate questions",
              "Questions validated against PMQuestionsV1 Pydantic schema before storage",
              "Questions stored in canonical_documents table (doc_type='pm_questions', status='approved')",
              "Questions displayed in workspace view with 'Answer Questions' form",
              "SSE stream shows real-time agent progress: 'PM Agent 1 working... PM Agent 2 complete...'",
              "Pipeline state updated to 'awaiting_user_answers'"
            ],
            "story_points": 8,
            "phase": "Phase 1",
            "epic_feature": "PM Discovery Workflow",
            "dependencies": ["WRK-100"],
            "technical_notes": "Orchestrator Core module (pure Python), Agent Service with anthropic.AsyncAnthropic, PMQuestionsV1 Pydantic schema validation, asyncio.gather for parallel execution, SSE streaming via FastAPI StreamingResponse"
          }
        },
        {
          "id": "story-pm-101",
          "type": "story",
          "data": {
            "id": "PM-101",
            "title": "Answer PM clarifying questions",
            "user_story": "As a user, I want to provide answers to the clarifying questions so that the system can generate a personalized Epic based on my inputs.",
            "acceptance_criteria": [
              "Form displays all PM questions with text areas for answers",
              "Validation: each answer must be at least 10 characters, all questions required",
              "POST /workspaces/{id}/answer saves answers to pipeline_state.context as JSON",
              "Pipeline state updated to 'epic_generation'",
              "User sees 'Generating Epic...' status message with SSE progress stream",
              "Validation errors displayed inline with specific field highlighting"
            ],
            "story_points": 3,
            "phase": "Phase 1",
            "epic_feature": "PM Discovery Workflow",
            "dependencies": ["PM-100"],
            "technical_notes": "HTMX form with hx-post, Pydantic validation for answer length, pipeline_state.context JSON field update, SSE connection initiated"
          }
        },
        {
          "id": "theme-epic-heading",
          "type": "heading",
          "level": 3,
          "content": "Theme: Epic Generation & Approval"
        },
        {
          "id": "story-epic-100",
          "type": "story",
          "data": {
            "id": "EPIC-100",
            "title": "Generate Canonical Epic",
            "user_story": "As a user, I want the system to generate a structured Canonical Epic based on my answers so that I have a comprehensive product definition document.",
            "acceptance_criteria": [
              "Orchestrator spawns 3 PM agents in parallel with idea description and user answers",
              "Each PM agent generates independent Epic proposal (vision, problem, goals, in scope, out of scope, requirements, roadmap)",
              "PM Mentor consolidates 3 proposals into single CanonicalEpicV1 document",
              "Epic validated against CanonicalEpicV1 Pydantic schema (fixed sections, typed blocks, no extra keys)",
              "Epic stored in canonical_documents table (doc_type='epic', status='draft')",
              "Epic displayed in workspace view with expandable/collapsible sections",
              "Sections rendered: Vision Statement, Problem/Opportunity, Business Goals, In Scope, Out of Scope, Requirements, Risks, Roadmap",
              "Pipeline state updated to 'epic_approval'"
            ],
            "story_points": 13,
            "phase": "Phase 1",
            "epic_feature": "PM Discovery Workflow",
            "dependencies": ["PM-101"],
            "technical_notes": "Agent Service parallel execution, CanonicalEpicV1 Pydantic schema, PM Mentor consolidation logic, canonical_documents INSERT with JSON content, Jinja2 template for Epic rendering"
          }
        },
        {
          "id": "story-epic-101",
          "type": "story",
          "data": {
            "id": "EPIC-101",
            "title": "Approve or regenerate Epic",
            "user_story": "As a user, I want to approve the Epic or request regeneration so that I can proceed with confidence in the product definition.",
            "acceptance_criteria": [
              "'Approve Epic' button updates canonical_documents.status='approved' and advances pipeline to 'architecture_start'",
              "'Regenerate Epic' button re-runs PM agents with same user answers, old Epic status set to 'superseded'",
              "User can inline-edit Epic section content (text edits saved to canonical_documents.content JSON)",
              "Manual edits display warning: 'Manual edits may not persist if Epic is regenerated'",
              "Approval triggers Architecture generation workflow automatically",
              "Regeneration shows SSE progress: 'Regenerating Epic... PM Agent 1 working...'"
            ],
            "story_points": 5,
            "phase": "Phase 1",
            "epic_feature": "PM Discovery Workflow",
            "dependencies": ["EPIC-100"],
            "technical_notes": "POST /workspaces/{id}/approve?stage=epic endpoint, HTMX inline editing for Epic blocks, status='superseded' for old versions, Orchestrator re-run logic"
          }
        },
        {
          "id": "theme-arch-heading",
          "type": "heading",
          "level": 3,
          "content": "Theme: Architecture Generation & Approval"
        },
        {
          "id": "story-arch-100",
          "type": "story",
          "data": {
            "id": "ARCH-100",
            "title": "Generate Canonical Architecture",
            "user_story": "As a user, I want the system to generate a technical architecture proposal so that I understand how the product will be built.",
            "acceptance_criteria": [
              "After Epic approval, Orchestrator spawns 3 Architect agents in parallel with Canonical Epic",
              "Each Architect agent generates architecture proposal (summary, components, data model, tech stack, key decisions)",
              "Supplemental Python MVP guidance enforced: Python/FastAPI required, no TypeScript/NestJS, no React SPA, canonical document store enforced",
              "Architect Mentor consolidates into CanonicalArchitectureV1 document (validated against Pydantic schema)",
              "Architecture stored in canonical_documents (doc_type='architecture', status='draft')",
              "Architecture displayed with sections: Summary, System Diagram (ASCII), Components, Data Model, Key Decisions, Tech Stack, Deployment",
              "Pipeline state updated to 'architecture_approval'",
              "SSE stream shows: 'Architect 1 working... Architect Mentor consolidating...'"
            ],
            "story_points": 13,
            "phase": "Phase 1",
            "epic_feature": "Architecture Generation",
            "dependencies": ["EPIC-101"],
            "technical_notes": "Architect agents with supplemental Python MVP guidance, CanonicalArchitectureV1 Pydantic validation, Architect Mentor enforces standards (rejects TypeScript/microservices/job queues), canonical_documents INSERT"
          }
        },
        {
          "id": "story-arch-101",
          "type": "story",
          "data": {
            "id": "ARCH-101",
            "title": "Approve or regenerate Architecture",
            "user_story": "As a user, I want to approve the Architecture or request changes so that I can proceed to backlog generation with confidence in the technical approach.",
            "acceptance_criteria": [
              "'Approve Architecture' button updates status='approved', advances pipeline to 'ba_start'",
              "'Regenerate Architecture' re-runs Architect agents with same Epic, old Architecture status='superseded'",
              "Ad-hoc Q&A feature: User can type question ('Why SQLite over PostgreSQL?') via text input",
              "Ad-hoc question triggers single agent call with Epic + Architecture context",
              "Ad-hoc response streamed via SSE and displayed inline below question",
              "Approval triggers BA (Backlog) generation workflow automatically"
            ],
            "story_points": 5,
            "phase": "Phase 1",
            "epic_feature": "Architecture Generation",
            "dependencies": ["ARCH-100"],
            "technical_notes": "POST /workspaces/{id}/approve?stage=architecture, ad-hoc Q&A SSE endpoint with single agent call, HTMX for question submission and response display"
          }
        },
        {
          "id": "theme-backlog-heading",
          "type": "heading",
          "level": 3,
          "content": "Theme: Backlog Generation & Approval"
        },
        {
          "id": "story-backlog-100",
          "type": "story",
          "data": {
            "id": "BACKLOG-100",
            "title": "Generate Canonical Backlog with INVEST user stories",
            "user_story": "As a user, I want the system to generate INVEST-compliant user stories so that I have an actionable development backlog.",
            "acceptance_criteria": [
              "After Architecture approval, Orchestrator spawns 3 BA agents with Epic + Architecture",
              "Each BA agent generates 20-40 user stories following INVEST principles (Independent, Negotiable, Valuable, Estimable, Small, Testable)",
              "BA Mentor consolidates into CanonicalBacklogV1 (validated against Pydantic schema)",
              "Backlog stored in canonical_documents (doc_type='backlog', status='draft')",
              "Each story includes: ID, Title, User Story, Acceptance Criteria (list), Story Points, Phase, Epic Feature, Dependencies (list), Technical Notes",
              "Stories grouped by Epic phase (Phase 1, Phase 2, Phase 3)",
              "Traceability: Each story links to Epic feature and phase via structured fields",
              "Pipeline state updated to 'backlog_approval'",
              "SSE stream shows: 'BA Agent 1 generating stories... BA Mentor consolidating...'"
            ],
            "story_points": 13,
            "phase": "Phase 1",
            "epic_feature": "Backlog Generation",
            "dependencies": ["ARCH-101"],
            "technical_notes": "BA agents enforce INVEST principles, CanonicalBacklogV1 Pydantic schema with story blocks, BA Mentor deduplication and consolidation, canonical_documents INSERT"
          }
        },
        {
          "id": "story-backlog-101",
          "type": "story",
          "data": {
            "id": "BACKLOG-101",
            "title": "Review and approve backlog",
            "user_story": "As a user, I want to review the backlog and approve it so that I can finalize my product definition and proceed to implementation or export.",
            "acceptance_criteria": [
              "Backlog displayed in table view with columns: Story ID, Title, Story Points, Phase, Status",
              "Filter dropdown or tabs: All Stories / Phase 1 / Phase 2 / Phase 3",
              "Click story row expands details: User Story, Acceptance Criteria (bulleted list), Dependencies, Technical Notes",
              "'Approve Backlog' button updates status='approved', marks workspace as complete",
              "'Regenerate Backlog' re-runs BA agents with same Epic + Architecture",
              "Approval enables export functionality (Markdown and JSON downloads)",
              "Story count and total story points displayed at top of table"
            ],
            "story_points": 5,
            "phase": "Phase 1",
            "epic_feature": "Backlog Generation",
            "dependencies": ["BACKLOG-100"],
            "technical_notes": "HTMX table with expandable rows, filtering via query params, POST /workspaces/{id}/approve?stage=backlog, Jinja2 template for backlog view"
          }
        },
        {
          "id": "theme-export-heading",
          "type": "heading",
          "level": 3,
          "content": "Theme: Export Functionality"
        },
        {
          "id": "story-export-100",
          "type": "story",
          "data": {
            "id": "EXPORT-100",
            "title": "Export workspace as Markdown",
            "user_story": "As a user, I want to download my workspace as a Markdown file so that I can share the complete product definition with my team or store it externally.",
            "acceptance_criteria": [
              "Export button visible after backlog approval",
              "GET /workspaces/{id}/export?format=markdown generates .md file",
              "Markdown structure: Epic sections (Vision, Problem, Goals, etc.) → Architecture sections (Summary, Components, Decisions) → Backlog (stories grouped by phase)",
              "Template-based generation using Jinja2 templates that read from canonical_documents table",
              "Filename format: {workspace_name}_{YYYY-MM-DD}.md",
              "Immediate synchronous download (no background job or queue)",
              "Export includes traceability: Story IDs, Epic feature references, phase labels"
            ],
            "story_points": 5,
            "phase": "Phase 1",
            "epic_feature": "Export Functionality",
            "dependencies": ["BACKLOG-101"],
            "technical_notes": "Export Service module, Jinja2 templates for Markdown formatting, canonical_documents query for epic/architecture/backlog, FastAPI Response with Content-Disposition header"
          }
        },
        {
          "id": "story-export-101",
          "type": "story",
          "data": {
            "id": "EXPORT-101",
            "title": "Export workspace as JSON (Jira-compatible)",
            "user_story": "As a user, I want to export my workspace as JSON so that I can import it into Jira or Linear without manual field mapping.",
            "acceptance_criteria": [
              "GET /workspaces/{id}/export?format=json generates .json file",
              "JSON structure: {workspace: {...}, epic: {...}, architecture: {...}, backlog: {stories: [...]}}",
              "Each story object includes: id, title, description (user story), acceptance_criteria (array), story_points, phase, epic_feature, dependencies (array), technical_notes",
              "Traceability fields: epic_id, feature_id, phase_id for each story",
              "Jira-compatible schema: Can be imported via Jira REST API or CSV import without manual mapping",
              "Direct JSON serialization from canonical_documents.content (no template)",
              "Filename format: {workspace_name}_{YYYY-MM-DD}.json"
            ],
            "story_points": 3,
            "phase": "Phase 1",
            "epic_feature": "Export Functionality",
            "dependencies": ["BACKLOG-101"],
            "technical_notes": "Python JSON serialization via json.dumps, canonical_documents query, Jira-compatible schema mapping, FastAPI JSONResponse"
          }
        },
        {
          "id": "theme-sse-heading",
          "type": "heading",
          "level": 3,
          "content": "Theme: Real-Time Streaming (SSE)"
        },
        {
          "id": "story-sse-100",
          "type": "story",
          "data": {
            "id": "SSE-100",
            "title": "Stream agent progress via Server-Sent Events",
            "user_story": "As a user, I want to see real-time updates while agents are working so that I know the system is actively processing my request.",
            "acceptance_criteria": [
              "GET /workspaces/{id}/stream returns SSE with Content-Type: text/event-stream",
              "Event types: {type: 'status', message: '...'}, {type: 'agent_start', agent: 'pm_1'}, {type: 'agent_output', agent: 'pm_1', content: '...'}, {type: 'agent_complete', agent: 'pm_1'}, {type: 'mentor_start'}, {type: 'mentor_complete'}",
              "EventSource client in frontend receives and displays status messages in workspace view",
              "Progress messages: 'PM Agent 1 working... PM Agent 2 complete... PM Mentor consolidating... Epic generation complete!'",
              "SSE stream automatically closes when Mentor finishes consolidation (stage completion)",
              "Auto-reconnect on disconnect (EventSource built-in retry with 3-second timeout)",
              "Proper SSE framing: data: prefix for each event, double newline (\\n\\n) delimiter between events"
            ],
            "story_points": 8,
            "phase": "Phase 1",
            "epic_feature": "Real-Time Streaming",
            "dependencies": ["PM-100", "EPIC-100", "ARCH-100", "BACKLOG-100"],
            "technical_notes": "FastAPI StreamingResponse with text/event-stream, asyncio.Queue for agent output messages, proper SSE framing (data: prefix, \\n\\n delimiter), EventSource API in frontend JavaScript"
          }
        },
        {
          "id": "theme-error-heading",
          "type": "heading",
          "level": 3,
          "content": "Theme: Error Handling & Resilience"
        },
        {
          "id": "story-error-100",
          "type": "story",
          "data": {
            "id": "ERROR-100",
            "title": "Retry failed LLM API calls",
            "user_story": "As a system, I want to automatically retry failed LLM API calls so that transient network or API errors don't block user workflows.",
            "acceptance_criteria": [
              "Agent Service implements retry logic with exponential backoff for failed anthropic API calls",
              "Retry sequence: First attempt → wait 0.5s → second attempt → wait 2s → third attempt (if configured)",
              "On each failure: Error logged to agent_logs table with error message and stack trace",
              "On final failure after all retries: User notified with message 'Agent failed to respond. [Retry] [Contact Support]'",
              "Retry button re-runs specific failed agent (not entire stage)",
              "Errors tracked: API timeout, rate limiting (429), invalid response format, network errors",
              "Success after retry: No user notification, workflow continues normally"
            ],
            "story_points": 5,
            "phase": "Phase 1",
            "epic_feature": "Error Handling & Resilience",
            "dependencies": ["PM-100", "EPIC-100", "ARCH-100", "BACKLOG-100"],
            "technical_notes": "Retry logic in Agent Service with exponential backoff via asyncio.sleep, agent_logs.error field for error messages, HTMX retry button UI"
          }
        },
        {
          "id": "story-error-101",
          "type": "story",
          "data": {
            "id": "ERROR-101",
            "title": "Validate canonical documents before saving",
            "user_story": "As a system, I want to validate all canonical documents against Pydantic schemas before saving so that data integrity is maintained and downstream processes can rely on consistent structure.",
            "acceptance_criteria": [
              "Schema Validation Layer validates canonical_documents.content against appropriate Pydantic schema (PMQuestionsV1, CanonicalEpicV1, CanonicalArchitectureV1, CanonicalBacklogV1) before INSERT",
              "On validation error: Mentor agent receives detailed Pydantic error message and regenerates output (max 3 attempts)",
              "Validation rules enforced: fixed section keys, allowed block types only, no extra keys (extra='forbid'), block ID uniqueness per section, table row consistency",
              "If all Mentor rewrite attempts fail: Error logged to agent_logs.error with full Pydantic ValidationError details",
              "User notification on final failure: 'Generation failed due to validation error. Please try again or contact support.'",
              "Successful validation: Document saved to canonical_documents with status='draft' or 'approved'"
            ],
            "story_points": 5,
            "phase": "Phase 1",
            "epic_feature": "Error Handling & Resilience",
            "dependencies": ["EPIC-100", "ARCH-100", "BACKLOG-100"],
            "technical_notes": "Pydantic ValidationError handling, Mentor rewrite loop in Orchestrator, agent_logs.error logging, user error notification UI"
          }
        },
        {
          "id": "theme-rerun-heading",
          "type": "heading",
          "level": 3,
          "content": "Theme: Re-run & Manual Overrides"
        },
        {
          "id": "story-rerun-100",
          "type": "story",
          "data": {
            "id": "RERUN-100",
            "title": "Re-run any pipeline stage",
            "user_story": "As a user, I want to re-run PM/Architecture/Backlog stages so that I can regenerate artifacts if I'm unsatisfied with the initial output.",
            "acceptance_criteria": [
              "'Re-run' button available for each completed stage (PM Questions, Epic, Architecture, Backlog)",
              "Re-run fetches original context from canonical_documents (Epic for Architecture re-run, Epic + Architecture for Backlog re-run)",
              "Orchestrator spawns agents with original inputs (user answers, Epic, Architecture)",
              "Old canonical document status updated to 'superseded' (soft version)",
              "New output validated and saved with status='draft'",
              "SSE stream shows regeneration progress: 'Regenerating Architecture... Architect 1 working...'",
              "User can re-run unlimited times (no artificial limit)",
              "Re-run preserves all superseded versions for future Phase 2 version history feature"
            ],
            "story_points": 8,
            "phase": "Phase 1",
            "epic_feature": "Re-run & Manual Overrides",
            "dependencies": ["EPIC-101", "ARCH-101", "BACKLOG-101"],
            "technical_notes": "Orchestrator re-run logic with context retrieval, canonical_documents status='superseded' updates, new document INSERT with status='draft', SSE progress streaming"
          }
        },
        {
          "id": "theme-repo-heading",
          "type": "heading",
          "level": 3,
          "content": "Theme: Repo View (Read-Only)"
        },
        {
          "id": "story-repo-100",
          "type": "story",
          "data": {
            "id": "REPO-100",
            "title": "List repo files (read-only)",
            "user_story": "As the AI Dev Orchestrator, I want a read-only API to list files in the repo so that I can discover existing modules, routes, models, and templates before changing anything.",
            "acceptance_criteria": [
              "GET /repo/files endpoint accepts query params: root (required, e.g. 'app'), glob (optional, e.g. '**/*.py'), max_files (optional, default 200)",
              "Endpoint enforces allow-list of roots: 'app', 'tests', 'templates', 'static', 'pyproject.toml', 'README.md'; rejects access to .env, secrets, .git, or any path outside allow-list",
              "Returns JSON with fields: {root: string, files: array of relative paths}",
              "Returns at most max_files entries; if exceeded, returns truncated: true flag",
              "Implemented in FastAPI under dedicated router (e.g. app/routers/repo_view.py), mounted on main app",
              "Endpoint is strictly read-only: no file writes, deletes, or git operations allowed",
              "Binary files (.pyc, .sqlite, .db) excluded from listings"
            ],
            "story_points": 3,
            "phase": "Phase 1",
            "epic_feature": "Repo View",
            "dependencies": ["ARCH-100"],
            "technical_notes": "Use pathlib for file traversal with glob support; apply strict allow-listing on roots and ignore binary files. This service is for LLM/Orchestrator introspection only and must not expose .env, secrets, or the .git directory."
          }
        },
        {
          "id": "story-repo-101",
          "type": "story",
          "data": {
            "id": "REPO-101",
            "title": "Get repo file content (read-only)",
            "user_story": "As the AI Dev Orchestrator, I want to fetch the contents of a specific file so that I can inspect existing implementations (routes, models, templates) and follow the established patterns.",
            "acceptance_criteria": [
              "GET /repo/file endpoint accepts path query parameter (relative to an allowed root from REPO-100 allow-list)",
              "Endpoint enforces allow-listed directories and blocks access to .env, secrets, .git, and any non-text file extensions (.pyc, .sqlite, .db, .png, .jpg, etc.)",
              "Supports optional max_bytes query param (default 16384 bytes / 16 KB); truncates responses above limit and adds truncated: true flag",
              "Returns JSON: {path: string, content: string, truncated: boolean}",
              "Only serves UTF-8 text files; non-text or binary files return 400 error with message: 'File is not a text file'",
              "Implemented in same repo_view router as REPO-100",
              "Strictly read-only: no write operations permitted"
            ],
            "story_points": 3,
            "phase": "Phase 1",
            "epic_feature": "Repo View",
            "dependencies": ["REPO-100"],
            "technical_notes": "This endpoint is read-only and intended for AI/Orchestrator consumption. Combine with REPO-100 so agents can list then fetch files, instead of guessing project structure. Use pathlib.read_text() with error handling for encoding issues."
          }
        },
        {
          "id": "phase1-totals",
          "type": "paragraph",
          "content": "Phase 1 Total: 22 stories, 117 story points. Estimated completion: 3 months with 2-3 full-stack engineers (39 story points per month average)."
        }
      ]
    },
    "phase_2_stories": {
      "blocks": [
        {
          "id": "phase2-heading",
          "type": "heading",
          "level": 2,
          "content": "Phase 2: Workflow Intelligence (Months 4-6)"
        },
        {
          "id": "phase2-summary",
          "type": "paragraph",
          "content": "Phase 2 adds workflow intelligence features: drift detection when users manually edit canonical documents, version history with rollback UI, idea library with search, PDF export, PostgreSQL migration, repo content search, and migration to third-party authentication providers."
        },
        {
          "id": "story-auth-200",
          "type": "story",
          "data": {
            "id": "AUTH-200",
            "title": "Migrate to third-party authentication (Auth0/Clerk)",
            "user_story": "As a system administrator, I want to migrate from magic-link authentication to a managed third-party provider so that users have more authentication options (social login, SSO) and the system has enterprise-grade security features.",
            "acceptance_criteria": [
              "Integration with Auth0 or Clerk SDK for OAuth2/OIDC authentication",
              "Support for email/password, Google, GitHub, Microsoft social login",
              "Migration path: Existing magic-link users can claim their accounts via email verification",
              "Sessions table preserved for audit purposes but deprecated for new logins",
              "JWT tokens issued by Auth0/Clerk replace internal session cookies",
              "All existing workspaces preserved and linked to new authentication identity",
              "Backward compatibility: Magic-link auth remains functional during migration period (30 days)"
            ],
            "story_points": 13,
            "phase": "Phase 2",
            "epic_feature": "Authentication & Security",
            "dependencies": ["AUTH-101"],
            "technical_notes": "Auth0 or Clerk SDK integration, account migration script linking sessions.email to new auth provider user_id, JWT verification via FastAPI dependency, deprecation notice for magic-link auth"
          }
        },
        {
          "id": "story-drift-100",
          "type": "story",
          "data": {
            "id": "DRIFT-100",
            "title": "Detect drift when user edits canonical documents",
            "user_story": "As a user, I want to be warned when my manual edits conflict with downstream artifacts so that I can resync or understand the impact.",
            "acceptance_criteria": [
              "System detects when user manually edits Epic after Architecture is approved",
              "Warning displayed: 'Epic has changed since Architecture was generated. Resync? [Yes] [No] [Review Changes]'",
              "Resync options: Full (regenerate Architecture + Backlog), Partial (regenerate Backlog only), None (keep current)",
              "Drift indicator shown on workspace detail: orange badge 'Out of sync' if drift detected",
              "Version comparison UI shows diff between current Epic and Epic used to generate Architecture"
            ],
            "story_points": 8,
            "phase": "Phase 2",
            "epic_feature": "Workflow Intelligence",
            "dependencies": ["EPIC-101", "ARCH-101"],
            "technical_notes": "Compare canonical_documents.content hashes or timestamps, diff visualization library, resync orchestration logic"
          }
        },
        {
          "id": "story-version-100",
          "type": "story",
          "data": {
            "id": "VERSION-100",
            "title": "Version history with rollback UI",
            "user_story": "As a user, I want to view version history of Epic/Architecture/Backlog and rollback to previous versions so that I can recover from unwanted changes.",
            "acceptance_criteria": [
              "'Version History' button on Epic/Architecture/Backlog views",
              "Version list shows: version number, timestamp, status (draft/approved/superseded)",
              "Click version shows diff vs. current version",
              "'Rollback to this version' copies old version content to new canonical document with status='draft'",
              "Rollback preserves current version as 'superseded' (no data loss)",
              "Version history paginated if more than 20 versions"
            ],
            "story_points": 8,
            "phase": "Phase 2",
            "epic_feature": "Workflow Intelligence",
            "dependencies": ["EPIC-101"],
            "technical_notes": "Query canonical_documents WHERE status='superseded' ORDER BY created_at DESC, diff library, rollback copies content to new row"
          }
        },
        {
          "id": "story-library-100",
          "type": "story",
          "data": {
            "id": "LIBRARY-100",
            "title": "Idea library with full-text search",
            "user_story": "As a user, I want to search my past workspaces and reference them when creating new ideas so that I can build on previous work.",
            "acceptance_criteria": [
              "Search bar on workspace list page",
              "Full-text search on workspace name, description, Epic content",
              "Search results ranked by relevance",
              "'Reference this idea' button copies Epic sections into new workspace as starting point",
              "Search filters: Status (active/archived), Phase (1/2/3), Date range"
            ],
            "story_points": 5,
            "phase": "Phase 2",
            "epic_feature": "Workflow Intelligence",
            "dependencies": ["WRK-101"],
            "technical_notes": "SQLite FTS5 or PostgreSQL tsvector for full-text search, search ranking, HTMX search results"
          }
        },
        {
          "id": "story-pdf-100",
          "type": "story",
          "data": {
            "id": "PDF-100",
            "title": "PDF export generation",
            "user_story": "As a user, I want to export my workspace as a professionally formatted PDF so that I can present it in meetings or share it with stakeholders.",
            "acceptance_criteria": [
              "GET /workspaces/{id}/export?format=pdf generates .pdf file",
              "PDF includes: Cover page with workspace name, Epic sections, Architecture sections, Backlog table",
              "Professional formatting: Table of contents, page numbers, headers/footers",
              "Syntax highlighting for code blocks in Architecture",
              "Filename: {workspace_name}_{YYYY-MM-DD}.pdf"
            ],
            "story_points": 5,
            "phase": "Phase 2",
            "epic_feature": "Export Functionality",
            "dependencies": ["EXPORT-100"],
            "technical_notes": "PDF generation library (WeasyPrint or ReportLab), HTML template → PDF conversion, CSS for styling"
          }
        },
        {
          "id": "story-migrate-100",
          "type": "story",
          "data": {
            "id": "MIGRATE-100",
            "title": "SQLite to PostgreSQL migration",
            "user_story": "As a system administrator, I want to migrate from SQLite to PostgreSQL when scale requires it so that the system can handle hundreds of concurrent users.",
            "acceptance_criteria": [
              "Migration script exports all data from SQLite to PostgreSQL",
              "Schema migrated: workspaces, canonical_documents, pipeline_state, agent_logs, sessions",
              "JSON columns migrated to JSONB with GIN indexes",
              "Connection string updated in environment variables",
              "No application code changes required (SQLAlchemy abstraction)",
              "Data integrity validation: row counts match, sample queries return same results",
              "Downtime window: < 1 hour for migration"
            ],
            "story_points": 8,
            "phase": "Phase 2",
            "epic_feature": "Scalability",
            "dependencies": [],
            "technical_notes": "SQLAlchemy migration script, PostgreSQL JSONB columns with GIN indexes, connection string environment variable"
          }
        },
        {
          "id": "story-repo-200",
          "type": "story",
          "data": {
            "id": "REPO-200",
            "title": "Search repo by content (read-only)",
            "user_story": "As the AI Dev Orchestrator, I want to search for symbols or strings across the repo so that I can quickly find where concepts like workspace, pipeline_state, or canonical_documents are implemented.",
            "acceptance_criteria": [
              "GET /repo/search endpoint accepts query params: q (required search string), glob (optional, e.g. '**/*.py'), max_results (optional, default 50)",
              "Searches only within allow-listed roots from REPO-100 (app, tests, templates, etc.)",
              "Returns JSON: {query: string, results: array of {path: string, line_number: int, snippet: string}}",
              "Snippet shows matched line plus 1 line before and after for context (max 3 lines total)",
              "Case-insensitive search by default",
              "Strictly read-only: no write operations",
              "Implemented in same repo_view router as REPO-100 and REPO-101"
            ],
            "story_points": 5,
            "phase": "Phase 2",
            "epic_feature": "Repo View",
            "dependencies": ["REPO-100", "REPO-101"],
            "technical_notes": "Use grep-like logic or simple string matching across text files. Allow-list enforcement prevents searching .env, secrets, .git. Useful for AI agents to locate where specific models, functions, or concepts are defined."
          }
        },
        {
          "id": "phase2-totals",
          "type": "paragraph",
          "content": "Phase 2 Total: 7 stories, 52 story points. Estimated completion: 2-3 months."
        }
      ]
    },
    "phase_3_stories": {
      "blocks": [
        {
          "id": "phase3-heading",
          "type": "heading",
          "level": 2,
          "content": "Phase 3: Growth & Expansion (Months 7-9)"
        },
        {
          "id": "phase3-summary",
          "type": "paragraph",
          "content": "Phase 3 adds growth features: read-only workspace sharing, API access for developers, user-selectable LLM models, horizontal scaling, and cloud storage migration."
        },
        {
          "id": "story-share-100",
          "type": "story",
          "data": {
            "id": "SHARE-100",
            "title": "Read-only workspace sharing",
            "user_story": "As a user, I want to share my workspace with teammates in read-only mode so that they can review my product definition without editing permissions.",
            "acceptance_criteria": [
              "'Share' button on workspace detail page",
              "Share modal: Enter email addresses, permission level (read-only)",
              "System creates workspace_shares records with shared_with_user_id and permission='read'",
              "Shared users see workspace in 'Shared with me' section",
              "Shared users can view all sections but cannot edit or approve",
              "Share owner can revoke access anytime"
            ],
            "story_points": 13,
            "phase": "Phase 3",
            "epic_feature": "Multi-User",
            "dependencies": ["WRK-101"],
            "technical_notes": "workspace_shares table, SQLAlchemy query modifications for shared workspaces, permission-based UI rendering"
          }
        },
        {
          "id": "story-api-100",
          "type": "story",
          "data": {
            "id": "API-100",
            "title": "API key authentication for programmatic access",
            "user_story": "As a developer, I want to create workspaces via API using API keys so that I can automate workflow creation in my CI/CD pipeline.",
            "acceptance_criteria": [
              "User can generate API keys in account settings",
              "API keys stored in api_keys table with hashed values",
              "POST /api/workspaces accepts API key in Authorization: Bearer header",
              "All workspace CRUD operations available via API",
              "Rate limiting: 100 requests/hour per API key",
              "API key scopes: read-only vs. full access"
            ],
            "story_points": 8,
            "phase": "Phase 3",
            "epic_feature": "API Access",
            "dependencies": ["WRK-100"],
            "technical_notes": "api_keys table, FastAPI dependency for API key auth, rate limiting per key, OpenAPI docs for API endpoints"
          }
        },
        {
          "id": "story-model-100",
          "type": "story",
          "data": {
            "id": "MODEL-100",
            "title": "User-selectable LLM models",
            "user_story": "As a user, I want to select which LLM model to use for each agent role (PM, Architect, BA) so that I can optimize for cost or quality.",
            "acceptance_criteria": [
              "Workspace settings: Model configuration per agent role",
              "Model options: Claude Opus 4, Claude Sonnet 4, Claude Haiku 4",
              "Model config stored in workspaces.model_config (JSONB)",
              "Agent Service reads model_config and uses specified model for each role",
              "Cost estimation shown: 'Using Opus for all agents: ~$2.50 per workflow'",
              "Default: Claude Sonnet 4 for all roles (backward compatible)"
            ],
            "story_points": 8,
            "phase": "Phase 3",
            "epic_feature": "User-Selectable Models",
            "dependencies": ["PM-100"],
            "technical_notes": "workspaces.model_config JSONB field, Agent Service reads config per role, cost estimation logic"
          }
        },
        {
          "id": "phase3-totals",
          "type": "paragraph",
          "content": "Phase 3 Total: 3 stories, 29 story points. Estimated completion: 2-3 months."
        }
      ]
    },
    "backlog_summary": {
      "blocks": [
        {
          "id": "backlog-summary-heading",
          "type": "heading",
          "level": 2,
          "content": "Backlog Summary"
        },
        {
          "id": "backlog-totals-table",
          "type": "table",
          "data": {
            "headers": ["Phase", "Stories", "Story Points", "Duration"],
            "rows": [
              ["Phase 1: Core Platform / MVP", "22", "117", "3 months"],
              ["Phase 2: Workflow Intelligence", "7", "52", "2-3 months"],
              ["Phase 3: Growth & Expansion", "3", "29", "2-3 months"],
              ["Total", "32", "198", "7-9 months"]
            ]
          }
        },
        {
          "id": "backlog-velocity",
          "type": "paragraph",
          "content": "Estimated team velocity: 39 story points per month (assumes 2-3 full-stack engineers with Python/FastAPI expertise). Phase 1 MVP deliverable in 3 months, full roadmap in 7-9 months."
        },
        {
          "id": "backlog-traceability",
          "type": "paragraph",
          "content": "All stories trace to Canonical Epic features and phases. All Phase 1 stories align with Canonical Architecture (Python/FastAPI, HTMX, SQLite, canonical document store). Technical notes reference specific architecture components (Orchestrator Core, Agent Service, Schema Validation Layer, Export Service, Repo View)."
        }
      ]
    }
  }
}